{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of Data Augmentation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/przemyslaw/.local/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "\n",
    "\n",
    "model_dir = \"trained_models\"\n",
    "os.environ[\"MODEL_DIR\"] = model_dir\n",
    "# from nlpaug.util.file.download import DownloadUtil\n",
    "# DownloadUtil.download_glove(model_name='glove.6B', dest_dir='trained_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to construct `augment` function that will be the most useful for data augmentation. It will transform one sentence to the other, preserving the meaning and it's label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(text: str) -> str:\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quick brown fox jumps over the lazy dog .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The quick brown fox jumps over the lazy dog .'\n",
    "augment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OCR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Texts:\n",
      "['The quicr brown fox jumps over the lazy dog.', 'The quick brown f0x jumps 0ver the lazy dog.', 'The quick brown fox jumps ovek the la2y dog.']\n"
     ]
    }
   ],
   "source": [
    "aug = nac.OcrAug()\n",
    "augmented_texts = aug.augment(text, n=3)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Texts:\")\n",
    "print(augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keyboard distance mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "The quUck brown fox jumps 9ver the lzzy dog.\n"
     ]
    }
   ],
   "source": [
    "aug = nac.KeyboardAug()\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random character insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "The *quick brown fox jyumps over the 2lazy dog.\n"
     ]
    }
   ],
   "source": [
    "aug = nac.RandomCharAug(action=\"insert\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random character substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "The quick 7rown fox jum)s over the laFy dog.\n"
     ]
    }
   ],
   "source": [
    "aug = nac.RandomCharAug(action=\"substitute\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random character swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "The quick brwon fox ujmps ovre the lazy dog.\n"
     ]
    }
   ],
   "source": [
    "aug = nac.RandomCharAug(action=\"swap\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random character deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "The qick brown fox umps over the azy dog.\n"
     ]
    }
   ],
   "source": [
    "aug = nac.RandomCharAug(action=\"delete\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary spelling mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Texts:\n",
      "['The quikly bIrown fox jumps over the lazy dig.', 'Tha qchick brown fox jumps other the lazy dog.', 'The qchick brouwn fox jumps over she lazy dog.']\n"
     ]
    }
   ],
   "source": [
    "aug = naw.SpellingAug()\n",
    "augmented_texts = aug.augment(text, n=3)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Texts:\")\n",
    "print(augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding similarity insertion (requires additional setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type: word2vec, glove or fasttext\n",
    "aug = naw.WordEmbsAug(\n",
    "    model_type='glove', model_path=model_dir+'GoogleNews-vectors-negative300.bin',\n",
    "    action=\"insert\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding similarity substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type: word2vec, glove or fasttext\n",
    "aug = naw.WordEmbsAug(\n",
    "    model_type='glove', model_path=model_dir+'GoogleNews-vectors-negative300.bin',\n",
    "    action=\"substitute\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF similiarity insertion (requires additional setup)\n",
    "#### TF-IDF similarity substitution (requires additional setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = naw.TfIdfAug(model_path=os.environ.get(\"MODEL_DIR\"), action=\"insert\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WordNet synonym replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/przemyslaw/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/przemyslaw/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "The speedy brown fox climb up terminated the lazy dog.\n"
     ]
    }
   ],
   "source": [
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLM word insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "while the occasional quick animated brown fox jumps over the lazy dog .\n"
     ]
    }
   ],
   "source": [
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"insert\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLM word substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "the quick brown fox looked over its lazy shore .\n"
     ]
    }
   ],
   "source": [
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"substitute\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PPDB synonym replacement (requires additional setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = naw.SynonymAug(aug_src='ppdb', model_path=os.environ.get(\"MODEL_DIR\") + 'ppdb-2.0-s-all')\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random word swapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "The brown quick fox jumps over the lazy dog.\n"
     ]
    }
   ],
   "source": [
    "aug = naw.RandomWordAug(action=\"swap\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random word deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "The brown fox the lazy dog.\n"
     ]
    }
   ],
   "source": [
    "aug = naw.RandomWordAug()\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous random word deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "The jumps over the lazy dog.\n"
     ]
    }
   ],
   "source": [
    "aug = naw.RandomWordAug(action='crop')\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "The quick b rown fox jum ps over the l azy dog.\n"
     ]
    }
   ],
   "source": [
    "aug = naw.SplitAug()\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backtranslation augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_translation_aug = naw.BackTranslationAug(\n",
    "    from_model_name='transformer.wmt19.en-de', \n",
    "    to_model_name='transformer.wmt19.de-en'\n",
    ")\n",
    "back_translation_aug.augment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Augmentation \n",
    "#### Insertion of sentence continuation with GPT-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "The quick brown fox jumps over the lazy dog . all new .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/przemyslaw/.local/lib/python3.6/site-packages/transformers/modeling_gpt2.py:759: FutureWarning: The `past` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "aug = nas.ContextualWordEmbsForSentenceAug(model_path='gpt2')\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarization with T5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "\n",
      "The history of natural language processing (NLP) generally started in the 1950s, although work can be \n",
      "found from earlier periods. In 1950, Alan Turing published an article titled \"Computing Machinery and \n",
      "Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence. \n",
      "The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian \n",
      "sentences into English. The authors claimed that within three or five years, machine translation would\n",
      "be a solved problem. However, real progress was much slower, and after the ALPAC report in 1966, \n",
      "which found that ten-year-long research had failed to fulfill the expectations, funding for machine \n",
      "translation was dramatically reduced. Little further research in machine translation was conducted \n",
      "until the late 1980s when the first statistical machine translation systems were developed.\n",
      "\n",
      "Augmented Text:\n",
      "the history of natural language processing started in the 1950s. in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" he proposed what is now called the Turing test as a criterion of intelligence.\n"
     ]
    }
   ],
   "source": [
    "article = \"\"\"\n",
    "The history of natural language processing (NLP) generally started in the 1950s, although work can be \n",
    "found from earlier periods. In 1950, Alan Turing published an article titled \"Computing Machinery and \n",
    "Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence. \n",
    "The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian \n",
    "sentences into English. The authors claimed that within three or five years, machine translation would\n",
    "be a solved problem. However, real progress was much slower, and after the ALPAC report in 1966, \n",
    "which found that ten-year-long research had failed to fulfill the expectations, funding for machine \n",
    "translation was dramatically reduced. Little further research in machine translation was conducted \n",
    "until the late 1980s when the first statistical machine translation systems were developed.\n",
    "\"\"\"\n",
    "\n",
    "aug = nas.AbstSummAug(model_path='t5-small', num_beam=3)\n",
    "augmented_text = aug.augment(article)\n",
    "print(\"Original:\")\n",
    "print(article)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
