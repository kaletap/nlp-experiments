{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface datasets libarary\n",
    "\n",
    "In this notebook we will explore the possibility to use huggingface/datasets library.\n",
    "\n",
    "It seems to be extremely easy to use and contains A LOT OF datasets: https://huggingface.co/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "from datasets import load_dataset, GenerateMode \n",
    "from tqdm import trange, tqdm\n",
    "# https://github.com/huggingface/datasets/blob/8b1a4d46616a755789090508450d35fb66253098/src/datasets/utils/download_manager.py#L34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/przemyslaw/.cache/huggingface/datasets/glue/mrpc/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset('glue', 'mrpc', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 0,\n",
       " 'label': 1,\n",
       " 'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3668"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 114,\n",
       " 'label': 0,\n",
       " 'sentence1': 'The Nasdaq composite index inched up 1.28 , or 0.1 percent , to 1,766.60 , following a weekly win of 3.7 percent .',\n",
       " 'sentence2': 'The technology-laced Nasdaq Composite Index .IXIC was off 24.44 points , or 1.39 percent , at 1,739.87 .'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/przemyslaw/.cache/huggingface/datasets/glue/mrpc/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'idx': 9,\n",
       " 'label': 1,\n",
       " 'sentence1': \"He said the foodservice pie business doesn 't fit the company 's long-term growth strategy .\",\n",
       " 'sentence2': '\" The foodservice pie business does not fit our long-term growth strategy .'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = load_dataset('glue', 'mrpc', split='validation')\n",
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'idx': 8,\n",
       "  'label': 0,\n",
       "  'sentence1': 'That compared with $ 35.18 million , or 24 cents per share , in the year-ago period .',\n",
       "  'sentence2': 'Earnings were affected by a non-recurring $ 8 million tax benefit in the year-ago period .'},\n",
       " {'idx': 11,\n",
       "  'label': 0,\n",
       "  'sentence1': 'Legislation making it harder for consumers to erase their debts in bankruptcy court won overwhelming House approval in March .',\n",
       "  'sentence2': 'Legislation making it harder for consumers to erase their debts in bankruptcy court won speedy , House approval in March and was endorsed by the White House .'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[8], train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The victims included seven Lebanese , four Egyptians , one Saudi and one Sudanese , the ministry official said . [SEP] State television said the dead included seven Lebanese , four Egyptians , one Saudi , one Sudanese and four whose nationalities were not named .'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = random.choice(train_dataset)\n",
    "' [SEP] '.join([example['sentence1'], example['sentence2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAP: gender balanced coreference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6934fb03151340689c3186e1220b583a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1748.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcefbeb0ee0c453d9d3c48a2d3dad37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1183.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset gap/default (download: 2.29 MiB, generated: 2.32 MiB, post-processed: Unknown size, total: 4.61 MiB) to /home/przemyslaw/.cache/huggingface/datasets/gap/default/0.1.0/496f1a9391428de6d2bbbc56f87ae03db397e137f863ee804f8cb0400dd61a5b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b550277bca4175a3f644b45ef19524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=480354.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e8df25900245fe8e895a6656dcec2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=110482.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432e90e79e604c819f662fa51680c096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=482874.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset gap downloaded and prepared to /home/przemyslaw/.cache/huggingface/datasets/gap/default/0.1.0/496f1a9391428de6d2bbbc56f87ae03db397e137f863ee804f8cb0400dd61a5b. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "gap_train = load_dataset(\"gap\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 'Cheryl Cassidy',\n",
       " 'A-coref': True,\n",
       " 'A-offset': 191,\n",
       " 'B': 'Pauline',\n",
       " 'B-coref': False,\n",
       " 'B-offset': 207,\n",
       " 'ID': 'development-1',\n",
       " 'Pronoun': 'her',\n",
       " 'Pronoun-offset': 274,\n",
       " 'Text': \"Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\",\n",
       " 'URL': 'http://en.wikipedia.org/wiki/List_of_Teachers_(UK_TV_series)_characters'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gap_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gap_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB: movie reviews with sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.06 MiB, post-processed: Unknown size, total: 207.28 MiB) to /home/przemyslaw/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086d4f6aaf8d47d2ae9e2f60d74826a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=84125825.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imdb downloaded and prepared to /home/przemyslaw/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train = load_dataset(\"imdb\", split=\"train\")\n",
    "len(imdb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': 'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNLI: Natural Language Inference\n",
    "https://huggingface.co/datasets/snli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88b675d82084984b9b7aa28d10b068e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1714.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0680e84abcae472284d4c2b1ffcf1a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=962.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset snli/plain_text (download: 90.17 MiB, generated: 65.51 MiB, post-processed: Unknown size, total: 155.68 MiB) to /home/przemyslaw/.cache/huggingface/datasets/snli/plain_text/1.0.0/bb1102591c6230bd78813e229d5dd4c7fbf4fc478cec28f298761eb69e5b537c...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072f0ae328ec4f42ad970d863c66ac1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1929.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4281fcc61fc9478b864e58ba45776443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1259440.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9144a0d85c0942c7be7b8d870f51818b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=65886400.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec70379b69f3495dba667a0be14b48ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1263568.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset snli downloaded and prepared to /home/przemyslaw/.cache/huggingface/datasets/snli/plain_text/1.0.0/bb1102591c6230bd78813e229d5dd4c7fbf4fc478cec28f298761eb69e5b537c. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "550152"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli_train = load_dataset('snli', split='train')\n",
    "len(snli_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opinosis: text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31757b4516294178b3ec3a520e09a9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1561.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468083c3cb9d4b8db06ce8e70ff62637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=816.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset opinosis/default (download: 739.65 KiB, generated: 723.90 KiB, post-processed: Unknown size, total: 1.43 MiB) to /home/przemyslaw/.cache/huggingface/datasets/opinosis/default/1.0.0/aab445995230d555dcbc237025a42cffaf09cc346ee9cd1c308635d3702fc029...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab89afe510e5408399f13ec8446fed43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=757398.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset opinosis downloaded and prepared to /home/przemyslaw/.cache/huggingface/datasets/opinosis/default/1.0.0/aab445995230d555dcbc237025a42cffaf09cc346ee9cd1c308635d3702fc029. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinosis_train = load_dataset(\"opinosis\", split=\"train\")\n",
    "len(opinosis_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_sents': \", and is very, very accurate .\\r\\n but for the most part, we find that the Garmin software provides accurate directions, whereever we intend to go .\\r\\n This function is not accurate if you don't leave it in battery mode say, when you stop at the Cracker Barrell for lunch and to play one of those trangle games with the tees .\\r\\n It provides immediate alternatives if the route from the online map program was inaccurate or blocked by an obstacle .\\r\\n I've used other GPS units, as well as GPS built into cars   and to this day NOTHING beats the accuracy of a Garmin GPS .\\r\\n It got me from point A to point B with 100% accuracy everytime .\\r\\n It has yet to disappoint, getting me everywhere with 100% accuracy .\\r\\n0 out of 5 stars Honest, accurate review, , PLEASE READ !\\r\\n Aside from that, every destination I've thrown at has been 100% accurate .\\r\\nIn closing, this is a fantastic GPS with some very nice features and is very accurate in directions .\\r\\n Plus, I've always heard that there are  quirks  with any GPS being accurate, having POIs, etc .\\r\\n DESTINATION TIME, , This is pretty accurate too .\\r\\n But, it's always very accurate .\\r\\n The map is pretty accurate and the Point of interest database also is good .\\r\\n Most of the times, this info was very accurate .\\r\\nI've even used it in the  pedestrian  mode, and it's amazing how accurate it is .\\r\\n  ONLY  is only accurate when an ad says,  Top sirloin steak, ONLY $1 .\\r\\n The most accurate review stated that these machines are adjunct to a good map and signs on the interstate .\\r\\n The directions are highly accurate down to a  T  .\\r\\n Depending on what you are using it for, it is a nice adjunct to a travel trip and the directions are accurate and usually the quickest, but not always .\\r\\n The screen is easy to see, the voice tells you where you are and it's very accurate .\\r\\n It was accurate to the minute when it told me when I would arrive home .\\r\\n0 out of 5 stars GPS Navigator doesn't navigate accurately on a straight road .\\r\\n I was familiar with the streets and only used the Nuvi to get an accurate arrival time estimate .\\r\\n but after that it is very easy and quite accurate to use .\\r\\n The accuracy at this point is very good .\\r\\nWhile the 255W routing seems generally accurate and logical, on my first use I discovered that it does have some errors in its internal map .\\r\\n Bottom line is I wanted a unit that is accurate and had reliable satellite connection .\\r\\n I've used it around town and find it to be extremely accurate .\\r\\nI found the maps to be inaccurate at first, but after I updated them from Garmin's website everything is golden .\\r\\n A lot of my friends' addresses are inaccurate by any GPS .\\r\\n It loads quickly, have pretty accurate directions, and can recalculate quickly when I miss a turn .\\r\\n Because the accuracy is good to the street address level, it may not be able to guide you to the exact location if your destination is inside a shopping mall .\\r\\nI updated to the latest 2010 map soon after I received the unit, so the map is accurate to me .\\r\\n I was blown away at the accuracy and routing capability this thing had .\\r\\n I used it the day I bought it,   and then this morning, and as soon as it comes on it is  ready to navigate  The only downfall of this product, and the only reason I did not give it 5 stars is the fact that the speed limit it displays for the road you are on isn't 100% accurate .\\r\\n If your looking for a nice, accurate GPS for not so much money, got with this one .\\r\\n0 out of 5 stars Inexpensive, accurate, plenty of features, August 6, 2009\\r\\n The only glitch I have found so far is that the speed limits are not 100% accurate, although the GPS, amazingly, is able to very accurately tell you how fast your vehicle is moving .\\r\\n I was a little disappointed in the inaccuracy of the posted speed limit, as I'm guilty of not paying close enough attention to those signs, especially w  interstate speed traps that are constantly changing up and down .\\r\\n The closest one that gives the most accurate route that I usually take is the Navigon .\\r\\n After 2 weeks, it has yet to make a mistake, and is always completely accurate ,  even to the point of telling me which side of the street my destination is on .\\r\\n It has worked well for local driving giving accurate directions for roads and streets .\\r\\nThe estimated time to arrival does not seem to calculate the travelling time accurately .\\r\\nAccuracy is as good as any other unit, they all sometimes tell you you have arrived when you haven't, or continue to tell you to turn when you're already there .\\r\\n Accuracy is determined by the maps .\\r\\n Less traveled rural roads will not be accurate on any unit .\\r\\n Accuracy is within a few yards .\\r\\nWhat the 255w does best is find a street address, business, point of interest, hospital or airport and give you turn, by, turn directions with amazing accuracy .\\r\\n The Garmin is loaded with very accurate maps that generally know the roads in even the remotest areas .\\r\\nI'm really glad I bought it though, and like the easy to read graphics, the voice used to tell you the name of the street you are to turn on, the uncannily accurate estimates of mileage and time of arrival at your destination .\\r\\nMy new Garmin 255w had very Easy Set Up, Accurate Directions to locations, User Friendly Unit to anyone in my vehicle who tried it .\\r\\n I had a GPS 10, years ago when I owned a boat that was difficult to use and with very poor accuracy so I had assumed that the road GPS wasn't any better .\\r\\n Practiced visiting places I already knew to see how accurate the directions and maps would be .\\r\\n Easy to use, excellent accuracy, nice and intuitive interface .\\r\\n The directions provided have all been quite accurate thus far .\\r\\n,  Very Accurate but with one small glitch I found ,  I'll explain in the CONS\\r\\nThis is a great GPS, it is so easy to use and it is always accurate .\\r\\nVery easy to operate and pretty accurate as well, only led me astray once and that was in northern Maine where roads are few and paved ones fewer .\\r\\n Easy to use and amazed at how accurate this item is .\\r\\nTo date it's been a very easy to use and accurate .\\r\\n Mounted really easily and has been very accurate .\\r\\n seems to be rather accurate .\\r\\n It was accurate on determing original directions and recalculating when necessary .\\r\\nHighly accurate, POIs are great .\\r\\n I can't believe how accurate and detailed the information estimated time of arrival,speed limits along the way,and detailed map of my route, to name a few .\\r\\n Speed of calculation, accuracy, and simplicity of operation are top notch .\\r\\n\",\n",
       " 'summaries': ['This unit is generally quite accurate.  \\r\\nSet-up and usage are considered to be very easy. \\r\\nThe maps can be updated, and tend to be reliable.',\n",
       "  \"The Garmin seems to be generally very accurate.\\r\\nIt's easy to use with an intuitive interface.\",\n",
       "  'It is very accurate, even in destination time.',\n",
       "  'Very accurate with travel and destination time.\\r\\nNegatives are not accurate with speed limits and rural roads.',\n",
       "  'Its accurate, fast and its simple operations make this a for sure buy.']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinosis_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1998102e162340aa970b1d499a08ef5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2392.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5fe5c464b146a4a7a52664fca7bb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=3755.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset polyglot_ner/en (download: 1.03 GiB, generated: 138.75 MiB, post-processed: Unknown size, total: 1.17 GiB) to /home/przemyslaw/.cache/huggingface/datasets/polyglot_ner/en/1.0.0/c929318589a30ee3f0dc5d53f1f99bf25a7ec16d3f319b3b671765c5ea464c99...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1934d578db714dac862c6c80c660ca22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1107018606.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset polyglot_ner downloaded and prepared to /home/przemyslaw/.cache/huggingface/datasets/polyglot_ner/en/1.0.0/c929318589a30ee3f0dc5d53f1f99bf25a7ec16d3f319b3b671765c5ea464c99. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "ner_train = load_dataset(\"polyglot_ner\", \"en\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423982"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ner_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '3',\n",
       " 'lang': 'en',\n",
       " 'ner': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " 'words': ['The', 'fruit', 'is', 'a', 'berry', 'or', 'capsule', '.']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_train[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style change detection\n",
    "https://huggingface.co/datasets/style_change_detection\n",
    "Has to use some zenodo to access the data, will have to figure it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment\n",
    "https://huggingface.co/datasets/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset sentiment140 (/home/przemyslaw/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f)\n",
      "100%|██████████| 1600000/1600000 [01:31<00:00, 17515.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 800000, 4: 800000})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"sentiment140\", split='train')\n",
    "sentiments = list()\n",
    "for d in tqdm(dataset):\n",
    "    sentiments.append(d['sentiment'])\n",
    "Counter(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': 'Mon Apr 06 22:19:49 PDT 2009',\n",
       " 'query': 'NO_QUERY',\n",
       " 'sentiment': 0,\n",
       " 'text': \"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\",\n",
       " 'user': 'scotthamilton'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuters\n",
    "https://huggingface.co/datasets/reuters21578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset reuters21578 (/home/przemyslaw/.cache/huggingface/datasets/reuters21578/ModHayes/1.0.0/ab980815695d5f9be6d5c0379001f574f528ea8075001a452eec938c0bb578c9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset(features: {'text': Value(dtype='string', id=None), 'topics': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'lewis_split': Value(dtype='string', id=None), 'cgis_split': Value(dtype='string', id=None), 'old_id': Value(dtype='string', id=None), 'new_id': Value(dtype='string', id=None), 'places': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'people': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'orgs': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'exchanges': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'date': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None)}, num_rows: 18323)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"reuters21578\", 'ModHayes', split='train')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cgis_split': '\"TRAINING-SET\"',\n",
       " 'date': '26-FEB-1987 16:10:43.67',\n",
       " 'exchanges': [],\n",
       " 'lewis_split': '\"TRAIN\"',\n",
       " 'new_id': '\"69\"',\n",
       " 'old_id': '\"5612\"',\n",
       " 'orgs': [],\n",
       " 'people': [],\n",
       " 'places': [],\n",
       " 'text': 'Reporting members of the National\\nSoybean Processors Association (NSPA) crushed 21,782,929\\nbushels of soybeans in the week ended Feb 25 compared with\\n22,345,718 bushels in the previous week and 16,568,000 in the\\nyear-ago week, the association said.\\n    It said total crushing capacity for members was 25,873,904\\nbushels vs 25,873,904 last week and 25,459,238 bushels last\\nyear.\\n    NSPA also said U.S. soybean meal exports in the week were\\n117,866 tonnes vs 121,168 tonnes a week ago and compared with\\n84,250 tonnes in the year-ago week.\\n    NSPA said the figures include only NSPA member firms.\\n Reuter\\n',\n",
       " 'title': 'U.S. WEEKLY SOYBEAN CRUSH 21,782,929 BUSHELS',\n",
       " 'topics': ['veg-oil', 'soybean', 'oilseed', 'meal-feed']}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 66\n",
    "dataset[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reporting members of the National\\nSoybean Processors Association (NSPA) crushed 21,782,929\\nbushels of soybeans in the week ended Feb 25 compared with\\n22,345,718 bushels in the previous week and 16,568,000 in the\\nyear-ago week, the association said.\\n    It said total crushing capacity for members was 25,873,904\\nbushels vs 25,873,904 last week and 25,459,238 bushels last\\nyear.\\n    NSPA also said U.S. soybean meal exports in the week were\\n117,866 tonnes vs 121,168 tonnes a week ago and compared with\\n84,250 tonnes in the year-ago week.\\n    NSPA said the figures include only NSPA member firms.\\n Reuter\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[num]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U.S. WEEKLY SOYBEAN CRUSH 21,782,929 BUSHELS'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[num]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['veg-oil', 'soybean', 'oilseed', 'meal-feed']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[num]['topics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Group\n",
    "https://huggingface.co/datasets/newsgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset newsgroups (/home/przemyslaw/.cache/huggingface/datasets/newsgroups/18828_alt.atheism/3.0.0/e6e5083c29aede4dcb47b3eb525f4cb2b34be7c1d24579e8d3c7921c275d04f1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['text'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"newsgroup\", '18828_alt.atheism', split='train')\n",
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Huggingface datasets contains a lot of useful datasets with infrastructure to work with them. Datasets include for example sentiment analysis (yelp, imdb) and textual entailment (natural language inference: snli, glue, anli, mnli, esnli) or question answering (drop, web questions). It also contains very large text datasets like c4 (\" colossal, cleaned version of Common Crawl's web crawl corpus.\"). Some dataset like this (only smaller) may be useful for training unsueprvised learning models like VAE.\n",
    "\n",
    "It's lacking for example part of speech (POS) tagging and it only has one NER task, but any text dataset can be added from a file, so that's good. Maybe the problem with those word-level tasks is that the lebels depend on the tokenization and preprocessing, I am not familiar with them that much.\n",
    "\n",
    "It should also integrate easily with other libraries. In particular, I want to use these datasets for training pytorch models with huggingface/transformers. I want to do it in a way that will make data loading quick (although I should probably not worry about it too much).\n",
    "\n",
    "Overall, I like it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
