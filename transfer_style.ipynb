{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style transfer exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "sys.path.append('../deep-latent-sequence-model/src')\n",
    "from data_utils import DataUtil\n",
    "from utils import reorder\n",
    "os.chdir('/home/przemyslaw/text-style-transfer/deep-latent-sequence-model')  # sorry for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../deep-latent-sequence-model/outputs_yelp/yelp_wd0.0_wb0.0_ws0.0_an3_pool5_klw0.1_lr0.001_t0.01_lm_bt_hard_avglen'\n",
    "model_path = os.path.join(model_dir, 'model.pt')\n",
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (word_emb): Embedding(9653, 128, padding_idx=0)\n",
       "    (layer): LSTM(128, 512, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (bridge): Linear(in_features=1024, out_features=512, bias=False)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): MlpAttn(\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (w_trg): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (w_att): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "    (ctx_to_readout): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    (readout): Linear(in_features=512, out_features=9653, bias=False)\n",
       "    (word_emb): Embedding(9653, 128, padding_idx=0)\n",
       "    (attr_emb): Embedding(2, 128, padding_idx=0)\n",
       "    (layer): LSTMCell(1152, 512)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (enc_to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "  (noise): NoiseLayer()\n",
       "  (LM0): LSTM_LM(\n",
       "    (embed): Embedding(9653, 128, padding_idx=0)\n",
       "    (dropout_in): Dropout(p=0.3, inplace=False)\n",
       "    (dropout_out): Dropout(p=0.3, inplace=False)\n",
       "    (lstm): LSTM(128, 512, batch_first=True)\n",
       "    (pred_linear): Linear(in_features=512, out_features=9653, bias=True)\n",
       "    (loss): CrossEntropyLoss()\n",
       "  )\n",
       "  (LM1): LSTM_LM(\n",
       "    (embed): Embedding(9653, 128, padding_idx=0)\n",
       "    (dropout_in): Dropout(p=0.3, inplace=False)\n",
       "    (dropout_out): Dropout(p=0.3, inplace=False)\n",
       "    (lstm): LSTM(128, 512, batch_first=True)\n",
       "    (pred_linear): Linear(in_features=512, out_features=9653, bias=True)\n",
       "    (loss): CrossEntropyLoss()\n",
       "  )\n",
       "  (LM): ModuleList(\n",
       "    (0): LSTM_LM(\n",
       "      (embed): Embedding(9653, 128, padding_idx=0)\n",
       "      (dropout_in): Dropout(p=0.3, inplace=False)\n",
       "      (dropout_out): Dropout(p=0.3, inplace=False)\n",
       "      (lstm): LSTM(128, 512, batch_first=True)\n",
       "      (pred_linear): Linear(in_features=512, out_features=9653, bias=True)\n",
       "      (loss): CrossEntropyLoss()\n",
       "    )\n",
       "    (1): LSTM_LM(\n",
       "      (embed): Embedding(9653, 128, padding_idx=0)\n",
       "      (dropout_in): Dropout(p=0.3, inplace=False)\n",
       "      (dropout_out): Dropout(p=0.3, inplace=False)\n",
       "      (lstm): LSTM(128, 512, batch_first=True)\n",
       "      (pred_linear): Linear(in_features=512, out_features=9653, bias=True)\n",
       "      (loss): CrossEntropyLoss()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams(object):\n",
    "    def __init__(self, **args):\n",
    "        self.pad = \"<pad>\"\n",
    "        self.unk = \"<unk>\"\n",
    "        self.bos = \"<s>\"\n",
    "        # self.eos = \"<\\s>\"\n",
    "        self.eos = \"</s>\"\n",
    "        self.pad_id = 0\n",
    "        self.unk_id = 1\n",
    "        self.bos_id = 2\n",
    "        self.eos_id = 3\n",
    "\n",
    "        self.batcher = \"sent\"\n",
    "        self.batch_size = 32\n",
    "        self.src_vocab_size = None\n",
    "        self.trg_vocab_size = None\n",
    "\n",
    "        self.inf = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationHparams(HParams):\n",
    "    dataset = \"Translate dataset\"\n",
    "    def __init__(self):\n",
    "        self.cuda = True\n",
    "        self.beam_size = 1\n",
    "        self.max_len = 300\n",
    "        self.batch_size = 32\n",
    "        self.merge_bpe = False\n",
    "        self.decode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = TranslationHparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_file_name = os.path.join(model_dir, \"hparams.pt\")\n",
    "train_hparams = torch.load(hparams_file_name)\n",
    "hparams = TranslationHparams()\n",
    "for k, v in train_hparams.__dict__.items():\n",
    "    setattr(hparams, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, x_mask, x_count, x_len, x_pos_emb_idxs, y_valid, y_mask, \\\n",
    "    y_count, y_len, y_pos_emb_idxs, y_neg, batch_size, end_of_epoch, index = data.next_test(test_batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/przemyslaw/.local/lib/python3.6/site-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "hs = model.translate(\n",
    "            x_valid, x_mask, x_len, y_neg, y_mask, y_len, beam_size=hparams.beam_size, max_len=hparams.max_len, poly_norm_m=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = reorder(hs, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_best_words = map(lambda wi: data.trg_i2w_list[0][wi], hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great job all from me .',\n",
       " \"best service i 've ever experienced .\",\n",
       " 'always great and timely .',\n",
       " 'love this place , you have good quality and quality staff .',\n",
       " \"awesome , excellent service , they do n't have any good food .\",\n",
       " 'best service ever .',\n",
       " \"i love the wings but they are n't worth the beyond great service .\",\n",
       " \"i 'll definitely b going back .\",\n",
       " 'loved the server , tried to charge me for a new ranch !',\n",
       " 'totally reccomend for any family restaurant in my opinion .',\n",
       " \"fantastic and that 's the inside of the restaurant is so perfect .\",\n",
       " 'the carrot and antipasto pancakes are tender and juicy and color .',\n",
       " 'was definitely recommended when i walked in .',\n",
       " 'place is in top of some local businesses .',\n",
       " 'drink was served in a fresh plastic cup .',\n",
       " 'so i ordered a salad dish .',\n",
       " 'also pretty good quality food .',\n",
       " 'highly recommended .',\n",
       " 'i felt good for the owners of this arizona staple .',\n",
       " 'it definitely rocks .',\n",
       " \"i love this place , do n't have to have to never .\",\n",
       " 'i love the little big box melt over my top .',\n",
       " \"for that reason , i 'll likely stay away from this establishment .\",\n",
       " 'good customer service .',\n",
       " 'they make me feel comfortable to shop for regulars .',\n",
       " 'they are always compassionate and understanding to my condition .',\n",
       " \"i wanted to give you zero stars but it would n't let me .\",\n",
       " 'that is fantastic !',\n",
       " 'the best experience i have ever had at an enterprise location .',\n",
       " 'very good .',\n",
       " 'fortunately , the store was a master down the street .',\n",
       " \"i 'm hooked because good customer service would have been .\",\n",
       " 'we enjoy and walk the mall .',\n",
       " 'first off , this place is beyond crowded !',\n",
       " 'also , most of the machines are taken all the time .',\n",
       " 'i recommend my membership after a week .',\n",
       " 'awesome gym and service !',\n",
       " 'great service .',\n",
       " 'he was helpful at first than kind as us if we were mind .',\n",
       " 'we started asking questions and he was very helpful and very friendly .',\n",
       " 'great food and quick service .',\n",
       " 'man , was helpful and friendly .',\n",
       " \"great food and affordable food and i could n't afford enough other complaints .\",\n",
       " 'the equipment is cute .',\n",
       " 'the restrooms are great , well maintained and paper everywhere .',\n",
       " 'it always feels clean .',\n",
       " 'make him put his tattoo here !',\n",
       " 'i have been in a row because of these reasons .',\n",
       " \"it 's a small place to eat here .\",\n",
       " 'kind rooms , beautiful , and charming .',\n",
       " 'i have had a great lunch here and i love it !',\n",
       " 'i went once and thanks to the happy hour .',\n",
       " 'great place .',\n",
       " 'this location on the other hand is nice , attentive , and professional .',\n",
       " 'i love the karaoke menu has been over for three months for now .',\n",
       " \"i 'm pretty sure you 'll walk out of there of happy hour !\",\n",
       " 'the best !',\n",
       " 'thank you !',\n",
       " 'this gym is always nice , and equipment is also broken or cute .',\n",
       " 'love this location .',\n",
       " 'equipment was outstanding .',\n",
       " 'great food and great service .',\n",
       " 'delicious !',\n",
       " \"the best thing is different that they are the separate towel '' .\"]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lists = map(lambda h: ' '.join([data.src_i2w[w] for w in h]), hs)\n",
    "list(word_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "Let's be honest: DataUtil class sucks. It has a lot of useless stuff, all we need is a vocabulary and a way to encode words to token indices (and decode them back). That should be extremely easy, but it's not. Let's implement something like that.\n",
    "\n",
    "All we need is a vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>', '<unk>', '<s>', '</s>', 'i', 'was', 'sadly', 'mistaken', '.', 'so']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.src_i2w[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, vocab: List[str]):\n",
    "        self.idx2word = vocab\n",
    "        self.word2idx = {word: i for i, word in enumerate(vocab)}\n",
    "        \n",
    "    def convert_ids_to_tokens(self, token_ids: Union[int, List[int]]):\n",
    "        if type(token_ids) == list:\n",
    "            return [self.idx2word[id_] for id_ in token_ids]\n",
    "        elif type(token_ids) == int:\n",
    "            return self.idx2word[ids]\n",
    "        else:\n",
    "            raise TypeError(f'Type of ids should be either list or int but is {type(ids)}')\n",
    "            \n",
    "    def convert_tokens_to_ids(self, tokens: Union[str, List[str]]):\n",
    "        if type(tokens) == list:\n",
    "            return [self.word2idx.get(token, 1) for token in tokens]\n",
    "        elif type(tokens) == str:\n",
    "            return self.word2idx.get(tokens, 1)\n",
    "        else:\n",
    "            raise TypeError(f'Type of ids should be either list or str but is {type(tokens)}')\n",
    "            \n",
    "    def convert_tokens_to_string(self, tokens: List[str]):\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def decode(self, token_ids: List[int], skip_special_tokens: bool = False):\n",
    "        if skip_special_tokens:\n",
    "            ids = [id_ for id_ in token_ids if id_ >= 4]\n",
    "        tokens = self.convert_ids_to_tokens(token_ids)\n",
    "        return self.convert_tokens_to_string(tokens)\n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return self.word2idx\n",
    "    \n",
    "    def tokenize(self, text: str):\n",
    "        \"\"\"Tokenizes a piece of text. Assumes that dots and commas etc. are taken care of before.\"\"\"\n",
    "        tokens = text.lower().split()\n",
    "        return self.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(data.src_i2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 103, 435, 154, 6179, 2444, 14, 41, 16, 170, 2337, 8]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer.tokenize('I very much like research job , it is my passion .')\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i very much like research job , it is my passion .'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
